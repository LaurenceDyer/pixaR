{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08a0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from scipy import ndimage\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import scipy.spatial as sp\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import SpatialDropout2D, GlobalAveragePooling2D\n",
    "\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3bd301",
   "metadata": {},
   "source": [
    "We have just under 1000 images labelled by the film that they were captured from. All images contain the main (Or a main) character from the film, those being:\n",
    "\n",
    "Cars            :- Lightning McQueen\n",
    "Finding Nemo    :- Nemo\n",
    "Monsters Inc    :- Mike (The Green One)\n",
    "The Incredibles :- Mr. Incredible\n",
    "Up              :- Carl (The Grandpa)\n",
    "Wall-E          :- Eva\n",
    "\n",
    "We chose these characters largely due to their high frequency in the image dataset, created here: \n",
    "            https://github.com/LaurenceDyer/pixaR\n",
    "            \n",
    "We aim to train a CNN model to correctly classify images of the main characters from these films. First, we import the fileset using opencv, then transform it in to an appropriately shaped tensor. This does require resizing the images (And thus losing quite some resolution), also performed via opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f8985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_files = glob.glob('*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701bd0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict = {0: \"Lightning McQueen\", 1: \"Nemo\", 2: \"Mike\", 3: \"Mr. Incredible\", 4: \"Carl\", 5: \"Eva\"}\n",
    "\n",
    "images = [cv2.imread(file) for file in jpg_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8e48ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTensor = np.empty((973,528,1280,3), dtype=np.float32)\n",
    "for (k, image) in enumerate(images):\n",
    "    imageTensor[k] = cv2.resize(image, dsize=(1280, 528))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88b894",
   "metadata": {},
   "source": [
    "We can use string modification to create a label set from the image names of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e20f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [re.sub(r\"[0-9]+.jpg\",\"\",x) for x in jpg_files]\n",
    "labels = [re.sub(r\"cars\",\"Lightning McQueen\",x) for x in labels]\n",
    "labels = [re.sub(r\"fnemo\",\"Nemo\",x) for x in labels]\n",
    "labels = [re.sub(r\"monsters\",\"Mike\",x) for x in labels]\n",
    "labels = [re.sub(r\"ti\",\"Mr. Incredible\",x) for x in labels]\n",
    "labels = [re.sub(r\"up\",\"Carl\",x) for x in labels]\n",
    "labels = [re.sub(r\"walle\",\"Eva\",x) for x in labels]\n",
    "\n",
    "labels = np.array(labels).reshape((973,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f61198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(973, 528, 1280, 3)\n",
      "(973, 1)\n"
     ]
    }
   ],
   "source": [
    "print(imageTensor.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34afb6",
   "metadata": {},
   "source": [
    "Great! All our tensors now have the correct shape for training. We can use sklearn to split our train/test data.\n",
    "\n",
    "We will also divide our integer values by 255 to normalize them to the range 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6312e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imageTensor/255.,labels,test_size=0.1,random_state=1337)\n",
    "print(\"Split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab3a3f",
   "metadata": {},
   "source": [
    "We reshape our labels into one-hot encoded (N-1) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768b20ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 1)\n",
      "(98, 1)\n"
     ]
    }
   ],
   "source": [
    "char_dict_inv = {v: k for k, v in char_dict.items()}\n",
    "\n",
    "y_train = np.vectorize(char_dict_inv.get)(y_train)\n",
    "y_test = np.vectorize(char_dict_inv.get)(y_test)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e40afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.reshape(X_test.shape[0],3,528,1280).astype(\"float32\")\n",
    "#X_train = X_train.reshape(X_train.shape[0],3,528,1280).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2aef4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 528, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50998312",
   "metadata": {},
   "source": [
    "Now we create our model. We choose to use a CNN because of its proven track record of high-quality modelling in computer vision. Because our dataset is quite small, it is important not to allow for excessive overfitting and as such we will utilise several dropout steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66153568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(528, 1280, 3), activation = 'relu'))  \n",
    "    model.add(SpatialDropout2D(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model.add(SpatialDropout2D(0.2))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    model.add(Dense(6, activation= 'softmax'))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623c28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 6001s 117s/step - loss: 1.7510 - accuracy: 0.2834 - val_loss: 1.7118 - val_accuracy: 0.2955\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 7479s 148s/step - loss: 1.6757 - accuracy: 0.3507 - val_loss: 1.6554 - val_accuracy: 0.3182\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 7418s 147s/step - loss: 1.6075 - accuracy: 0.3723 - val_loss: 1.6107 - val_accuracy: 0.3295\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 7234s 144s/step - loss: 1.6129 - accuracy: 0.3659 - val_loss: 1.6218 - val_accuracy: 0.3295\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 7239s 144s/step - loss: 1.5638 - accuracy: 0.3901 - val_loss: 1.5768 - val_accuracy: 0.3409\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 7319s 145s/step - loss: 1.5720 - accuracy: 0.3863 - val_loss: 1.5806 - val_accuracy: 0.3409\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 7016s 140s/step - loss: 1.5524 - accuracy: 0.3863 - val_loss: 1.5726 - val_accuracy: 0.3636\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 6961s 138s/step - loss: 1.5371 - accuracy: 0.3939 - val_loss: 1.5636 - val_accuracy: 0.3409\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 7029s 139s/step - loss: 1.5107 - accuracy: 0.4053 - val_loss: 1.5586 - val_accuracy: 0.3523\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 7202s 144s/step - loss: 1.5316 - accuracy: 0.3977 - val_loss: 1.5221 - val_accuracy: 0.4205\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "\n",
    "history = model.fit(X_train,y_train, validation_split=0.1, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd8ecbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshow_history\u001b[49m(history\u001b[38;5;241m.\u001b[39mhistory)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'show_history' is not defined"
     ]
    }
   ],
   "source": [
    "show_history(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef69ea26",
   "metadata": {},
   "source": [
    "As we can see, our validation accuracy has increased to roughly 42% and is still increasing as of 10 epochs, with our loss at 1.5 and dropping. This is very reassuring as overfitting was likely to be the biggest challenge in this analysis. Computationally speaking, this took my laptop almost a full day, and so I cannot continue training the model but am extremely satisfied with it and imagine its accuracy would keep increasing well above 50% if left for one or two hundred epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
